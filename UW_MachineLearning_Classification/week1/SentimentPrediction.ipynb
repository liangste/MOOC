{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use Pandas\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define data types for the columns we are importing\n",
    "dtype_dict = {'name' : str, 'review' : str, 'rating' : int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import .csv file as DataFrame object\n",
    "products = pd.read_csv('amazon_baby.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper function to remove punctuations from reviews\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# proprocess empty reviews and apply our punctuation function\n",
    "products = products.fillna({'review':''}) \n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop 3-star ratings\n",
    "products = products[products['rating'] != 3]\n",
    "\n",
    "# reindex DataFrame\n",
    "products = products.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split into training and test data \n",
    "\n",
    "with open('module-2-assignment-test-idx.json') as json_file:\n",
    "    test_indices = json.load(json_file)\n",
    "\n",
    "with open('module-2-assignment-train-idx.json') as json_file:\n",
    "    train_indices = json.load(json_file)\n",
    "    \n",
    "test_data = products.ix[test_indices]\n",
    "train_data = products.ix[train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build the word count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LogisticRegression model on training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "sentiment_model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "sentiment_model.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Number of coefficients in the sentiment model %f\" % len(sentiment_model.coef_[0]))\n",
    "print(\"### Number of positive coefficients is \", len([x for x in sentiment_model.coef_[0] if x >= 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_predict(model, test_matrix):\n",
    "    return [+1 if s >= 0 else -1 for s in model.decision_function(test_matrix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_predict(sentiment_model, sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_model.predict(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = lambda x: 1.0/(1+exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_prob_predict(model, test_matrix):\n",
    "    return [logit(s) for s in model.decision_function(test_matrix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[x for x in my_prob_predict(sentiment_model, sample_test_matrix)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_model.predict_proba(sample_test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[round(x, 3) for x in my_prob_predict(sentiment_model, sample_test_matrix)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use the entire test data\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use decision scores for ranking, as the decision values differ enough for ranking\n",
    "test_data['decision'] = sentiment_model.decision_function(test_matrix)\n",
    "test_data['prediction'] = sentiment_model.predict(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_20 = test_data.sort_values(by='decision', ascending=False).head(20)\n",
    "top_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bottom_20 = test_data.sort_values(by='decision', ascending=True).head(20)\n",
    "bottom_20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_n = len(test_data)\n",
    "correct_n = len(test_data[test_data['sentiment'] == test_data['prediction']])\n",
    "print correct_n / float(total_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn another classifier with fewer words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_model = linear_model.LogisticRegression(n_jobs=-1)\n",
    "simple_model.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a DataFrame containing the words and their evaluated coefficients\n",
    "simple_words = pd.DataFrame()\n",
    "simple_words['word'] = significant_words\n",
    "simple_words['coef'] = simple_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display words with positive coefficients\n",
    "simple_words_pos = simple_words[simple_words['coef'] >= 0].sort_values(by='coef', ascending=False)\n",
    "\n",
    "print(\"There are %d evaluated positive words in the simple model\" % len(simple_words_pos))\n",
    "print simple_words_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check with all words\n",
    "\n",
    "all_words = list(vectorizer.vocabulary_.keys())\n",
    "vectorizer_word_set = CountVectorizer(vocabulary=all_words) # limit to 20 words\n",
    "train_matrix_word_set = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_set = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_words = pd.DataFrame()\n",
    "sentiment_words['word'] = all_words\n",
    "sentiment_words['sentiment_coef'] = sentiment_model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sentiment_words[sentiment_words['word'].isin(simple_words_pos['word'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accuracy of the sentiment model on training data\n",
    "train_data['sentiment'] = train_data['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "train_data['prediction'] = my_predict(sentiment_model, train_matrix)\n",
    "\n",
    "total_n = len(train_data)\n",
    "correct_n = len(train_data[train_data['sentiment'] == train_data['prediction']])\n",
    "print correct_n / float(total_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accuracy of the simple model on training data\n",
    "train_data['prediction'] = my_predict(simple_model, train_matrix_word_subset)\n",
    "\n",
    "total_n = len(train_data)\n",
    "correct_n = len(train_data[train_data['sentiment'] == train_data['prediction']])\n",
    "print correct_n / float(total_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accuracy of the sentiment model on test data\n",
    "test_data['sentiment'] = test_data['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "test_data['prediction'] = my_predict(sentiment_model, test_matrix)\n",
    "\n",
    "total_n = len(test_data)\n",
    "correct_n = len(test_data[test_data['sentiment'] == test_data['prediction']])\n",
    "print correct_n / float(total_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# accuracy of the simple model on test data\n",
    "test_data['sentiment'] = test_data['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "test_data['prediction'] = my_predict(simple_model, test_matrix_word_subset)\n",
    "\n",
    "total_n = len(test_data)\n",
    "correct_n = len(test_data[test_data['sentiment'] == test_data['prediction']])\n",
    "print correct_n / float(total_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Class classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print round(float(sum(train_data['sentiment'] == 1)) / len(train_data), 2)\n",
    "print round(float(sum(test_data['sentiment'] == 1)) / len(test_data), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
