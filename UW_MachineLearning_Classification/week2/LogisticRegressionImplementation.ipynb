{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'name': str, 'review': str, 'rating': int, 'sentiment':int}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby_subset.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Stop Pacifier Sucking without tears with Thumb...\n",
       "1      Nature's Lullabies Second Year Sticker Calendar\n",
       "2      Nature's Lullabies Second Year Sticker Calendar\n",
       "3                          Lamaze Peekaboo, I Love You\n",
       "4    SoftPlay Peek-A-Boo Where's Elmo A Children's ...\n",
       "5                            Our Baby Girl Memory Book\n",
       "6    Hunnt&reg; Falling Flowers and Birds Kids Nurs...\n",
       "7    Blessed By Pope Benedict XVI Divine Mercy Full...\n",
       "8    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "9    Cloth Diaper Pins Stainless Steel Traditional ...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try listing names of the first 10 products\n",
    "products['name'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of positive reviews 26579\n"
     ]
    }
   ],
   "source": [
    "# number of positive reviews\n",
    "print \"number of positive reviews\", len(products[products['sentiment'] >= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of negative reviews 26493\n"
     ]
    }
   ],
   "source": [
    "# number of negative reviews\n",
    "print \"number of negative reviews\", len(products[products['sentiment'] <= 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the important words\n",
    "with open('important_words.json') as wfile:\n",
    "    important_words = json.load(wfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'baby', u'one', u'great', u'love', u'use', u'would', u'like', u'easy', u'little', u'seat', u'old', u'well', u'get', u'also', u'really', u'son', u'time', u'bought', u'product', u'good', u'daughter', u'much', u'loves', u'stroller', u'put', u'months', u'car', u'still', u'back', u'used', u'recommend', u'first', u'even', u'perfect', u'nice', u'bag', u'two', u'using', u'got', u'fit', u'around', u'diaper', u'enough', u'month', u'price', u'go', u'could', u'soft', u'since', u'buy', u'room', u'works', u'made', u'child', u'keep', u'size', u'small', u'need', u'year', u'big', u'make', u'take', u'easily', u'think', u'crib', u'clean', u'way', u'quality', u'thing', u'better', u'without', u'set', u'new', u'every', u'cute', u'best', u'bottles', u'work', u'purchased', u'right', u'lot', u'side', u'happy', u'comfortable', u'toy', u'able', u'kids', u'bit', u'night', u'long', u'fits', u'see', u'us', u'another', u'play', u'day', u'money', u'monitor', u'tried', u'thought', u'never', u'item', u'hard', u'plastic', u'however', u'disappointed', u'reviews', u'something', u'going', u'pump', u'bottle', u'cup', u'waste', u'return', u'amazon', u'different', u'top', u'want', u'problem', u'know', u'water', u'try', u'received', u'sure', u'times', u'chair', u'find', u'hold', u'gate', u'open', u'bottom', u'away', u'actually', u'cheap', u'worked', u'getting', u'ordered', u'came', u'milk', u'bad', u'part', u'worth', u'found', u'cover', u'many', u'design', u'looking', u'weeks', u'say', u'wanted', u'look', u'place', u'purchase', u'looks', u'second', u'piece', u'box', u'pretty', u'trying', u'difficult', u'together', u'though', u'give', u'started', u'anything', u'last', u'company', u'come', u'returned', u'maybe', u'took', u'broke', u'makes', u'stay', u'instead', u'idea', u'head', u'said', u'less', u'went', u'working', u'high', u'unit', u'seems', u'picture', u'completely', u'wish', u'buying', u'babies', u'won', u'tub', u'almost', u'either']\n"
     ]
    }
   ],
   "source": [
    "print important_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-processing\n",
    "products = products.fillna({'review' : ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    return text.translate(None, string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baby one great love use would like easy little seat old well get also really son time bought product good daughter much loves stroller put months car still back used recommend first even perfect nice bag two using got fit around diaper enough month price go could soft since buy room works made child keep size small need year big make take easily think crib clean way quality thing better without set new every cute best bottles work purchased right lot side happy comfortable toy able kids bit night long fits see us another play day money monitor tried thought never item hard plastic however disappointed reviews something going pump bottle cup waste return amazon different top want problem know water try received sure times chair find hold gate open bottom away actually cheap worked getting ordered came milk bad part worth found cover many design looking weeks say wanted look place purchase looks second piece box pretty trying difficult together though give started anything last company come returned maybe took broke makes stay instead idea head said less went working high unit seems picture completely wish buying babies won tub almost either\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "for word in important_words:\n",
    "    print word,\n",
    "    products[word] = products['review_clean'].apply(lambda s : s.split().count(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Question. How many reviews contain the word perfect?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(products[products['perfect'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_frame, features, output):\n",
    "    data_frame['constant'] = 1\n",
    "    features = ['constant'] + features\n",
    "\n",
    "    features_frame = data_frame[features]\n",
    "    feature_matrix = features_frame.as_matrix()\n",
    "    \n",
    "    output_array = data_frame[output]\n",
    "    output_array = output_array.as_matrix()\n",
    "    \n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_matrix, sentiment = get_numpy_data(products, important_words, 'sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Question: How many features are there in the feature_matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53072, 194) features\n"
     ]
    }
   ],
   "source": [
    "print feature_matrix.shape, 'features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz Question: Assuming that the intercept is present, how does the number of features in feature_matrix relate to the number of features in the logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "they are equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of important_words ( 193 ) + 1\n"
     ]
    }
   ],
   "source": [
    "print 'size of important_words (', len(important_words), ') + 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "produces probablistic estimate for P(y_i = +1 | x_i, w).\n",
    "estimate ranges between 0 and 1.\n",
    "'''\n",
    "def predict_probability(feature_matrix, coefficients):\n",
    "    # Take dot product of feature_matrix and coefficients  \n",
    "    score = np.dot(feature_matrix, coefficients)\n",
    "    \n",
    "    # Compute P(y_i = +1 | x_i, w) using the link function\n",
    "    predictions = 1.0 / (1.0 + np.exp(-score))\n",
    "    \n",
    "    # return predictions\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following outputs must match \n",
      "------------------------------------------------\n",
      "correct_predictions           = [ 0.98201379  0.26894142]\n",
      "output of predict_probability = [ 0.98201379  0.26894142]\n"
     ]
    }
   ],
   "source": [
    "dummy_feature_matrix = np.array([[1.,2.,3.], [1.,-1.,-1]])\n",
    "dummy_coefficients = np.array([1., 3., -1.])\n",
    "\n",
    "correct_scores      = np.array( [ 1.*1. + 2.*3. + 3.*(-1.),          1.*1. + (-1.)*3. + (-1.)*(-1.) ] )\n",
    "correct_predictions = np.array( [ 1./(1+np.exp(-correct_scores[0])), 1./(1+np.exp(-correct_scores[1])) ] )\n",
    "\n",
    "print 'The following outputs must match '\n",
    "print '------------------------------------------------'\n",
    "print 'correct_predictions           =', correct_predictions\n",
    "print 'output of predict_probability =', predict_probability(dummy_feature_matrix, dummy_coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):     \n",
    "    # Compute the dot product of errors and feature\n",
    "    derivative = np.dot(errors, feature)\n",
    "    # Return the derivative\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_log_likelihood(feature_matrix, sentiment, coefficients):\n",
    "    indicator = (sentiment==+1)\n",
    "    scores = np.dot(feature_matrix, coefficients)\n",
    "    lp = np.sum((indicator-1)*scores - np.log(1. + np.exp(-scores)))\n",
    "    return lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def logistic_regression(feature_matrix, sentiment, initial_coefficients, step_size, max_iter):\n",
    "    coefficients = np.array(initial_coefficients) # make sure it's a numpy array\n",
    "    for itr in xrange(max_iter):\n",
    "        # Predict P(y_i = +1|x_1,w) using your predict_probability() function\n",
    "        predictions = predict_probability(feature_matrix, coefficients)\n",
    "\n",
    "        # Compute indicator value for (y_i = +1)\n",
    "        indicator = (sentiment==+1)\n",
    "\n",
    "        # Compute the errors as indicator - predictions\n",
    "        errors = indicator - predictions\n",
    "\n",
    "        for j in xrange(len(coefficients)): # loop over each coefficient\n",
    "            # Recall that feature_matrix[:,j] is the feature column associated with coefficients[j]\n",
    "            # compute the derivative for coefficients[j]. Save it in a variable called derivative\n",
    "            # YOUR CODE HERE\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, j])\n",
    "\n",
    "            # add the step size times the derivative to the current coefficient\n",
    "            # YOUR CODE HERE\n",
    "            coefficients[j] += step_size * derivative\n",
    "\n",
    "        # Checking whether log likelihood is increasing\n",
    "        if itr <= 15 or (itr <= 100 and itr % 10 == 0) or (itr <= 1000 and itr % 100 == 0) \\\n",
    "        or (itr <= 10000 and itr % 1000 == 0) or itr % 10000 == 0:\n",
    "            lp = compute_log_likelihood(feature_matrix, sentiment, coefficients)\n",
    "            print 'iteration %*d: log likelihood of observed labels = %.8f' % \\\n",
    "                (int(np.ceil(np.log10(max_iter))), itr, lp)\n",
    "            print lp\n",
    "    return coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "initial_coefficients = np.zeros(feature_matrix.shape[1])\n",
    "step_size = 1e-7\n",
    "max_iter = 301"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration   0: log likelihood of observed labels = -36780.91768478\n",
      "-36780.9176848\n",
      "iteration   1: log likelihood of observed labels = -36775.13434712\n",
      "-36775.1343471\n",
      "iteration   2: log likelihood of observed labels = -36769.35713564\n",
      "-36769.3571356\n",
      "iteration   3: log likelihood of observed labels = -36763.58603240\n",
      "-36763.5860324\n",
      "iteration   4: log likelihood of observed labels = -36757.82101962\n",
      "-36757.8210196\n",
      "iteration   5: log likelihood of observed labels = -36752.06207964\n",
      "-36752.0620796\n",
      "iteration   6: log likelihood of observed labels = -36746.30919497\n",
      "-36746.309195\n",
      "iteration   7: log likelihood of observed labels = -36740.56234821\n",
      "-36740.5623482\n",
      "iteration   8: log likelihood of observed labels = -36734.82152213\n",
      "-36734.8215221\n",
      "iteration   9: log likelihood of observed labels = -36729.08669961\n",
      "-36729.0866996\n",
      "iteration  10: log likelihood of observed labels = -36723.35786366\n",
      "-36723.3578637\n",
      "iteration  11: log likelihood of observed labels = -36717.63499744\n",
      "-36717.6349974\n",
      "iteration  12: log likelihood of observed labels = -36711.91808422\n",
      "-36711.9180842\n",
      "iteration  13: log likelihood of observed labels = -36706.20710739\n",
      "-36706.2071074\n",
      "iteration  14: log likelihood of observed labels = -36700.50205049\n",
      "-36700.5020505\n",
      "iteration  15: log likelihood of observed labels = -36694.80289716\n",
      "-36694.8028972\n",
      "iteration  20: log likelihood of observed labels = -36666.39512033\n",
      "-36666.3951203\n",
      "iteration  30: log likelihood of observed labels = -36610.01327118\n",
      "-36610.0132712\n",
      "iteration  40: log likelihood of observed labels = -36554.19728365\n",
      "-36554.1972837\n",
      "iteration  50: log likelihood of observed labels = -36498.93316099\n",
      "-36498.933161\n",
      "iteration  60: log likelihood of observed labels = -36444.20783914\n",
      "-36444.2078391\n",
      "iteration  70: log likelihood of observed labels = -36390.00909449\n",
      "-36390.0090945\n",
      "iteration  80: log likelihood of observed labels = -36336.32546144\n",
      "-36336.3254614\n",
      "iteration  90: log likelihood of observed labels = -36283.14615871\n",
      "-36283.1461587\n",
      "iteration 100: log likelihood of observed labels = -36230.46102347\n",
      "-36230.4610235\n",
      "iteration 200: log likelihood of observed labels = -35728.89418769\n",
      "-35728.8941877\n",
      "iteration 300: log likelihood of observed labels = -35268.51212683\n",
      "-35268.5121268\n",
      "[  5.16220157e-03   1.55656966e-02  -8.50204675e-03   6.65460842e-02\n",
      "   6.58907629e-02   5.01743882e-03  -5.38601484e-02  -3.50488413e-03\n",
      "   6.47945868e-02   4.54356263e-02   3.98353364e-03   2.00775410e-02\n",
      "   3.01350011e-02  -2.87115530e-02   1.52161964e-02   2.72592062e-04\n",
      "   1.19448177e-02  -1.82461935e-02  -1.21706420e-02  -4.15110334e-02\n",
      "   2.76820391e-03   1.77031999e-02  -4.39700067e-03   4.49764014e-02\n",
      "   9.90916464e-03   8.99239081e-04  -1.36219516e-03   1.26859357e-02\n",
      "   8.26466695e-03  -2.77426972e-02   6.10128809e-04   1.54084501e-02\n",
      "  -1.32134753e-02  -3.00512492e-02   2.97399371e-02   1.84087080e-02\n",
      "   2.86178752e-03  -1.05768015e-02  -6.57350362e-04  -1.01476555e-02\n",
      "  -4.79579528e-03   7.50891810e-03   4.27938289e-03   3.06785501e-03\n",
      "  -2.20317661e-03   9.57273354e-03   9.91666827e-05  -1.98462567e-02\n",
      "   1.75702722e-02   1.55478612e-03  -1.77375440e-02   9.78324102e-03\n",
      "   1.17031606e-02  -7.35345937e-03  -6.08714030e-03   6.43766808e-03\n",
      "   1.07159665e-02  -3.05345476e-03   7.17190727e-03   5.73320003e-03\n",
      "   4.60661876e-03  -5.20588421e-03   6.71012331e-03   9.03281814e-03\n",
      "   1.74563147e-03   6.00279979e-03   1.20181744e-02  -1.83594607e-02\n",
      "  -6.91010811e-03  -1.38687273e-02  -1.50406590e-02   5.92353611e-03\n",
      "   5.67478991e-03  -5.28786220e-03   3.08147864e-03   5.53751236e-03\n",
      "   1.49917916e-02  -3.35666000e-04  -3.30695153e-02  -4.78990943e-03\n",
      "  -6.41368859e-03   7.99938935e-03  -8.61390444e-04   1.68052959e-02\n",
      "   1.32539901e-02   1.72307051e-03   2.98030675e-03   8.58284300e-03\n",
      "   1.17082481e-02   2.80825907e-03   2.18724016e-03   1.68824711e-02\n",
      "  -4.65973741e-03   1.51368285e-03  -1.09509122e-02   9.17842898e-03\n",
      "  -1.88572281e-04  -3.89820373e-02  -2.44821005e-02  -1.87023714e-02\n",
      "  -2.13943485e-02  -1.29690465e-02  -1.71378670e-02  -1.37566767e-02\n",
      "  -1.49770449e-02  -5.10287978e-03  -2.89789761e-02  -1.48663194e-02\n",
      "  -1.28088380e-02  -1.07709355e-02  -6.95286915e-03  -5.04082164e-03\n",
      "  -9.25914404e-03  -2.40427481e-02  -2.65927785e-02  -1.97320937e-03\n",
      "  -5.04127508e-03  -7.00791912e-03  -3.48088523e-03  -6.40958916e-03\n",
      "  -4.07497010e-03  -6.30054296e-03  -1.09187932e-02  -1.26051900e-02\n",
      "  -1.66895314e-03  -7.76418781e-03  -5.15960485e-04  -1.94199551e-03\n",
      "  -1.24761586e-03  -5.01291731e-03  -9.12049191e-03  -7.22098801e-03\n",
      "  -8.31782981e-03  -5.60573348e-03  -1.47098335e-02  -9.31520819e-03\n",
      "  -2.22034402e-03  -7.07573098e-03  -5.10115608e-03  -8.93572862e-03\n",
      "  -1.27545713e-02  -7.04171991e-03  -9.76219676e-04   4.12091713e-04\n",
      "   8.29251160e-04   2.64661064e-03  -7.73228782e-03   1.53471164e-03\n",
      "  -7.37263060e-03  -3.73694386e-03  -3.81416409e-03  -1.64575145e-03\n",
      "  -3.31887732e-03   1.22257832e-03   1.36699286e-05  -3.01866601e-03\n",
      "  -1.02826343e-02  -1.06691327e-02   2.23639046e-03  -9.87424798e-03\n",
      "  -1.02192048e-02  -3.41330929e-03   3.34489960e-03  -3.50984516e-03\n",
      "  -6.26283150e-03  -7.22419943e-03  -5.47016154e-03  -1.25063947e-02\n",
      "  -2.47805699e-03  -1.60017985e-02  -6.40098934e-03  -4.26644386e-03\n",
      "  -1.55376990e-02   2.31349237e-03  -9.06653337e-03  -6.30012672e-03\n",
      "  -1.21010303e-02  -3.02578875e-03  -6.76289718e-03  -5.65498722e-03\n",
      "  -6.87050239e-03  -1.18950595e-02  -1.86489236e-04  -1.15230476e-02\n",
      "   2.81533219e-03  -8.10150295e-03  -1.00062131e-02   4.02037651e-03\n",
      "  -5.44300346e-03   2.85818985e-03   1.19885003e-04  -6.47587687e-03\n",
      "  -1.14493516e-03  -7.09205934e-03]\n"
     ]
    }
   ],
   "source": [
    "coefficients = logistic_regression(feature_matrix, sentiment, initial_coefficients,\n",
    "                                  step_size, max_iter)\n",
    "print coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: As each iteration of gradient ascent passes, does the log likelihood increase or decrease?\n",
    "\n",
    "#### should increase!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: How many reviews were predicted to have positive sentiment?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = np.dot(feature_matrix, coefficients)\n",
    "predicted_sentiments = np.array([+1 if s > 0 else -1 for s in scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25126\n"
     ]
    }
   ],
   "source": [
    "print np.where(predicted_sentiments == 1)[0].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: What is the accuracy of the model on predictions made above? (round to 2 digits of accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74114410612\n"
     ]
    }
   ],
   "source": [
    "print sum(predicted_sentiments==sentiment) / float(len(sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefficients = list(coefficients[1:]) # exclude intercept\n",
    "word_coefficient_tuples = [(word, coefficient) for word, coefficient in zip(important_words, coefficients)]\n",
    "word_coefficient_tuples = sorted(word_coefficient_tuples, key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: Which word is not present in the top 10 \"most positive\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'great', 0.00023011095749548731),\n",
       " (u'love', 0.00022919083832962883),\n",
       " (u'easy', 0.00022415562487307223),\n",
       " (u'little', 0.00015544207691545761),\n",
       " (u'loves', 0.00015417337068725665),\n",
       " (u'well', 0.00010086492750064691),\n",
       " (u'perfect', 0.00010084183986166351),\n",
       " (u'old', 6.7367412681327744e-05),\n",
       " (u'nice', 6.1407869651496232e-05),\n",
       " (u'soft', 5.9646857678954867e-05)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz question: Which word is not present in the top 10 \"most negative\" words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'waste', -8.3670176248573709e-05),\n",
       " (u'return', -9.2913592987661818e-05),\n",
       " (u'monitor', -9.3995419225179145e-05),\n",
       " (u'disappointed', -9.9820964146925048e-05),\n",
       " (u'back', -0.00010483521247037151),\n",
       " (u'even', -0.00011109959075874404),\n",
       " (u'get', -0.00011269149624664059),\n",
       " (u'work', -0.00012016286066171855),\n",
       " (u'money', -0.00013753480269165251),\n",
       " (u'product', -0.00015748674652922082)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_coefficient_tuples[-11:-1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ml2]",
   "language": "python",
   "name": "conda-env-ml2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
